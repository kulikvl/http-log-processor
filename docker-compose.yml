version: '3'
services:
  zookeeper:
    platform: linux/x86_64
    image: confluentinc/cp-zookeeper:7.1.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000 # for heartbeats and timeouts

  broker:
    image: confluentinc/cp-kafka:7.1.0
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092" # for kafka clients to connect
      - "9101:9101" # for JMX (Java Management Extensions) to monitor and manage the Kafka broker
    environment:
      KAFKA_BROKER_ID: 1 # uniquely identify the broker within the cluster
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181' # how to connect to Zookeeper for cluster management
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT # security protocols for the listeners
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092 # how clients can connect to the broker
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 # replication factor for the internal consumers offsets topic
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1  # minimum number of replicas that must acknowledge a write (transaction commit) for it to be considered successful
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # replication factor for the transaction state log, a special internal topic that Kafka uses to store metadata about transactions
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0 # how long to wait before starting the first rebalance
      KAFKA_JMX_PORT: 9101
      KAFKA_LOG_RETENTION_MS: 60000 # how long messages are kept
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO" # log levels for Kafka components

  grafana:
    image: "grafana/grafana:8.4.5"
    ports:
     - "3000:3000"
    environment:
      GF_PATHS_DATA : /var/lib/grafana
      GF_SECURITY_ADMIN_PASSWORD : kafka
    volumes:
     - ./grafana/provisioning:/etc/grafana/provisioning
     - ./grafana/dashboards:/var/lib/grafana/dashboards
    container_name: grafana
    depends_on:
     - prometheus

  prometheus:
    image: "prom/prometheus:v2.34.0"
    ports:
     - "9090:9090"
    volumes:
     - ./etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command: "--config.file=/etc/prometheus/prometheus.yml"
    container_name: prometheus

  jmx-kafka:
    platform: linux/x86_64
    image: "sscaling/jmx-prometheus-exporter"
    ports:
     - "5556:5556"
    environment:
     CONFIG_YML : "/etc/jmx_exporter/config.yml"
    volumes:
     - ./etc/jmx_exporter/config_kafka.yml:/etc/jmx_exporter/config.yml
    container_name: jmx-kafka
    depends_on:
     - broker

  kafka-ui:
    image: provectuslabs/kafka-ui:master
    container_name: kafka-ui
    ports:
      - "4000:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=DevEnv
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=broker:29092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - broker

  clickhouse-server:
    image: yandex/clickhouse-server
    ports:
      - "8123:8123" # HTTP API Port for HTTP requests, used by JDBC, ODBC, and web interfaces.
      - "9000:9000" # Native Protocol port (ClickHouse TCP protocol). Used by ClickHouse apps and processes like clickhouse-server, clickhouse-client, and native ClickHouse tools. Used for inter-server communication for distributed queries.
      - "9009:9009" # inter-server communication port or other purposes like HTTP interface with compression
    ulimits: # ulimits are constraints set by the operating system that limit the resources that processes can consume. Ensure that a service does not consume more resources than the system can handle
      nproc: 65535 # maximum number of processes that can be created
      nofile: # limits on the number of open files for the container:
        soft: 262144 # soft limit, which can be changed by the process up to the hard limit.
        hard: 262144 # hard limit, the maximum number of open files allowed for the container. 
    container_name: clickhouse
    hostname: clickhouse

  ch-proxy:
    build: docker/ch-proxy
    ports:
      - 8124:8124
    restart: always
    depends_on:
      - clickhouse-server
    container_name: ch-proxy

  http-log-kafka-producer:
    build: docker/http-log-kafka-producer
    platform: linux/amd64
    restart: always
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "broker:29092"
      KAFKA_PRODUCER_DELAY_MS: 1000
    depends_on:
      - broker
    container_name: log-producer

  http-log-processor:
    build:
      http-log-processor
    environment:
      KAFKA_BROKER: "broker:29092"
      KAFKA_TOPIC: "http_log"
      KAFKA_GROUP: "data-engineering-task-reader"
      DB: "clickhouse:9000"
      DB_DRIVER: "clickhouse"
      WRITER_BUFFER_SIZE: 1024
      WRITE_INTERVAL_SECONDS: 10
    container_name: http-log-processor
    depends_on:
      - broker
      - clickhouse-server
